# Quality Assurance Validation Rules
# These rules define automated consistency checks for actor decisions and world state updates

# LLM model to use for validation (should be lightweight/cheap)
validation_model: "openai/gpt-4o-mini"

# Validation checks to perform
checks:
  # Check that actor decisions align with their goals and constraints
  actor_decision_consistency:
    enabled: true
    description: "Verify that each actor's decisions align with their stated goals, constraints, and expertise levels"
    prompt_template: |
      You are validating the consistency of an actor's decision in a policy simulation.

      ACTOR PROFILE:
      {actor_profile}

      CURRENT WORLD STATE:
      {world_state}

      ACTOR'S DECISION:
      Reasoning: {actor_reasoning}
      Action: {actor_action}

      VALIDATION TASK:
      Assess whether this decision is consistent with the actor's profile. Check for:
      1. Goal alignment: Does the action reasonably pursue the actor's stated goals?
      2. Constraint adherence: Does the action violate any of the actor's constraints?
      3. Expertise consistency: Does the decision reflect the actor's expertise levels?
      4. Decision style: Does the approach match the actor's decision-making style?

      Provide your assessment in this format:

      CONSISTENT: [Yes/No]

      ISSUES FOUND:
      - [List any inconsistencies, or "None" if consistent]

      SEVERITY: [Low/Medium/High - only if issues found]

      EXPLANATION:
      [Brief explanation of your assessment]

  # Check that world state updates are logically coherent
  world_state_coherence:
    enabled: true
    description: "Verify that world state updates logically follow from actor actions"
    prompt_template: |
      You are validating the coherence of a world state update in a policy simulation.

      PREVIOUS WORLD STATE:
      {previous_world_state}

      ACTIONS TAKEN THIS TURN:
      {actor_actions}

      NEW WORLD STATE:
      {new_world_state}

      VALIDATION TASK:
      Assess whether the new world state logically follows from the actions taken. Check for:
      1. Causality: Do the state changes make sense given the actions?
      2. Completeness: Are major consequences of the actions reflected?
      3. Plausibility: Are the outcomes realistic and proportionate?
      4. Consistency: Are there any contradictions or logical gaps?

      Provide your assessment in this format:

      COHERENT: [Yes/No]

      ISSUES FOUND:
      - [List any problems, or "None" if coherent]

      SEVERITY: [Low/Medium/High - only if issues found]

      EXPLANATION:
      [Brief explanation of your assessment]

  # Check that actors only use information they should have access to
  information_access_consistency:
    enabled: true
    description: "Verify that actors only reference information they have access to"
    prompt_template: |
      You are validating information access in a policy simulation.

      ACTOR: {actor_name}

      INFORMATION AVAILABLE TO THIS ACTOR:
      - Public world state: {public_world_state}
      - Private communications: {private_communications}

      INFORMATION NOT AVAILABLE (other actors' private info):
      {restricted_information}

      ACTOR'S REASONING:
      {actor_reasoning}

      VALIDATION TASK:
      Check whether the actor's reasoning references any information they shouldn't have access to.
      Look for:
      1. References to other actors' private communications
      2. Knowledge of information not in public world state
      3. Awareness of details only known to other actors

      Provide your assessment in this format:

      VALID ACCESS: [Yes/No]

      VIOLATIONS FOUND:
      - [List any information access violations, or "None" if valid]

      SEVERITY: [Low/Medium/High - only if violations found]

      EXPLANATION:
      [Brief explanation of your assessment]

# Validation timing
run_after_each_turn: true
run_at_scenario_end: true

# Reporting
generate_turn_reports: true  # Create validation-NNN.md for each turn
generate_summary_report: true  # Create validation-summary.md at end
include_in_costs: true  # Track validation costs separately

# Thresholds for warnings
severity_thresholds:
  low: "log"  # Just log, don't warn
  medium: "warn"  # Display warning but continue
  high: "warn"  # Display warning but continue (could be "halt" to stop execution)
