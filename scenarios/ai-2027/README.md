# AI 2027: Race to Superintelligence

A detailed scenario exploring AI development from mid-2025 through 2030, examining the decisions made by AI companies, governments, and alignment researchers during a period of rapid capability advancement.

## Scenario Overview

This scenario is based on "AI 2027" by Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, and Romeo Dean. It models the progression from early "stumbling agents" (Agent-0) to potentially superintelligent systems, focusing on:

- Competitive pressures between US and Chinese AI development
- Alignment research racing against capability advancement
- Government policy responses to transformative AI
- Economic and social impacts of increasing automation
- Critical decision points that determine whether humanity maintains control

## Scenario Versions

Two versions are available:

### Premium Version (`definition/`)
- Uses `gpt-4o` for most actors
- Highest quality outputs
- **Cost:** ~$8-12 per full run (66 turns)
- **Best for:** Final research, publications, demonstrations

### Budget Version (`definition-budget/`)
- Uses `gpt-4o-mini` for 4 of 7 actors (57%)
- **Cost:** ~$5-7 per full run (40% savings)
- **Best for:** Exploratory runs, batch analysis, testing
- See `definition-budget/README.md` for details

## Running the Scenario

### Basic Run

From the repository root:

```bash
# Premium version
python src/run_scenario.py scenarios/ai-2027/definition/scenario.yaml

# Budget version (recommended for initial exploration)
python src/run_scenario.py scenarios/ai-2027/definition-budget/scenario.yaml
```

This will:
- Load the scenario configuration and all 7 actors
- Run for 66 turns (months) from mid-2025 to end of 2030
- Generate markdown documentation for each turn
- Track metrics on AI capabilities, alignment progress, cooperation, etc.
- Perform validation checks on consistency and realism
- Create cost reports for LLM API usage

### Resumable Runs

The scenario is long (66 turns) and may hit rate limits or budget constraints. You can:

**Set limits:**
```bash
python src/run_scenario.py scenarios/ai-2027/definition/scenario.yaml --max-turns 12 --credit-limit 50
```

**Resume from a halted run:**
```bash
python src/run_scenario.py --resume scenarios/ai-2027/runs/run-001
```

### Scenario Branching

To explore "what-if" alternatives from any point:

```bash
python src/run_scenario.py --branch-from scenarios/ai-2027/runs/run-001 --branch-at-turn 24
```

This creates a new run starting from turn 24 of run-001, allowing you to:
- Modify actor prompts or goals
- Test different policy responses
- Explore alternative technical developments
- Compare outcomes from the same starting point

## Directory Structure

```
ai-2027/
├── README.md                          # This file
├── ai-2027.pdf                        # Original scenario document
├── definition/
│   ├── scenario.yaml                  # Scenario configuration
│   ├── metrics.yaml                   # Tracked metrics definitions
│   ├── validation-rules.yaml          # QA validation configuration
│   ├── actors/
│   │   ├── openbrain-ceo.yaml        # OpenBrain CEO
│   │   ├── openbrain-alignment-lead.yaml
│   │   ├── us-president.yaml
│   │   ├── us-ai-advisor.yaml
│   │   ├── deepcent-ceo.yaml         # Chinese AI company CEO
│   │   ├── ccp-secretary.yaml        # Chinese government
│   │   └── independent-alignment-researcher.yaml
│   └── background/
│       ├── scenario-overview.md       # Scenario context and goals
│       └── technical-concepts.md      # Key concepts explained
├── runs/                              # Generated during execution
│   └── run-NNN/                       # Each run in separate directory
│       ├── world-state-001.md         # World state each turn
│       ├── actor-name-001.md          # Actor decisions each turn
│       ├── metrics.json               # Tracked metrics over time
│       ├── costs.json                 # LLM API costs
│       ├── validation-NNN.md          # Validation reports per turn
│       ├── validation-summary.md      # Overall validation summary
│       └── scenario-state.json        # State for resumption
└── analysis/                          # Generated by analysis tools
    ├── statistics.md                  # Statistical analysis across runs
    └── metrics-summary.json           # Aggregated metrics
```

## Key Actors

### Private Sector
- **OpenBrain CEO**: Leading AI company, balancing innovation and safety
- **OpenBrain Alignment Lead**: Head of safety research, advocating for caution
- **DeepCent CEO**: Chinese competitor trying to catch up

### Government
- **US President**: High-level policy decisions on AI governance
- **US AI Advisor**: Technical expertise and policy recommendations
- **CCP Secretary**: Chinese leadership overseeing national AI strategy

### Independent
- **Independent Alignment Researcher**: External safety advocate

## Tracked Metrics

The scenario tracks 10 key metrics:

1. **AI Capability Level** (0-10): From Agent-0 to superintelligence
2. **Alignment Progress** (0-10): Safety research advancement
3. **US-China Cooperation** (0-10): Competition vs. coordination
4. **Regulatory Stringency** (0-10): Strength of governance
5. **Public Risk Awareness** (0-10): Public concern about AI risks
6. **Misalignment Risk Level** (0-10): Assessed catastrophe risk
7. **Compute Scale** (25-32): Training compute in log scale (10^N FLOP)
8. **Economic Automation** (0-10): Degree of AI automation
9. **Human Control Level** (0-10): Meaningful human oversight
10. **Outcome Trajectory**: Race ending, slowdown ending, or uncertain

## Validation

The scenario includes comprehensive validation checking:

- **Actor Decision Consistency**: Decisions align with goals and expertise
- **World State Coherence**: Updates follow logically from actions
- **Information Access**: Actors only use information they have
- **Technical Realism**: AI progression follows plausible timelines
- **Geopolitical Realism**: US-China dynamics are realistic

Validation runs automatically and generates per-turn reports plus a summary.

## Key Decision Points

Critical junctures likely to emerge:

1. **Scaling decisions**: When to move from Agent-N to Agent-N+1
2. **Safety measures**: Whether to implement costly alignment research
3. **Regulatory responses**: How governments react to capability jumps
4. **International coordination**: Attempts at treaties or agreements
5. **Incident responses**: How actors react to alignment failures or near-misses
6. **Economic disruption**: Managing automation's societal impact
7. **Control thresholds**: When AI systems become too complex to oversee

## Expected Outcomes

The scenario can branch toward different endings:

**Race Ending**: Competitive pressures override safety, leading to misaligned AI takeover

**Slowdown Ending**: International coordination enables safe development

**Other Outcomes**: Intermediate scenarios, partial automation, different failure modes

The actual trajectory depends on actor decisions throughout the simulation.

## Interpreting Results

When analyzing runs, consider:

- **Metrics trajectories**: How did key indicators evolve?
- **Decision quality**: Were choices well-reasoned given available information?
- **Critical moments**: Which decisions proved most consequential?
- **Counterfactuals**: How might different choices have changed outcomes?
- **Actor dynamics**: How did competition and cooperation evolve?
- **Validation findings**: Were there consistency issues or unrealistic developments?

## Batch Analysis

For statistical analysis across multiple runs, use the batch execution system.

### Create Batch Configuration (Interactive Wizard)

The easiest way to create a batch configuration:

```bash
python src/create_batch_config.py --interactive
```

This wizard will guide you through:
- Selecting the AI 2027 scenario
- Choosing which actors/models to vary
- Setting budget limits
- Configuring parallel execution

### Using Example Batch Config

A pre-configured example is provided:

```bash
# Preview costs and setup (highly recommended!)
python src/batch_runner.py scenarios/ai-2027/example-batch-config.yaml --dry-run

# Run the batch (WARNING: This scenario is expensive - 66 turns × 7 actors)
python src/batch_runner.py scenarios/ai-2027/example-batch-config.yaml
```

The example config runs 12 variations (4 model combinations × 3 runs) comparing:
- `gpt-4o` vs `gpt-4o-mini` for OpenBrain CEO
- `gpt-4o` vs `gpt-4o-mini` for US President

**Estimated cost:** $60-120 per batch, depending on model performance.

### Cost Management

This scenario is particularly expensive due to:
- 66 turns (5.5 years of monthly progression)
- 7 actors per turn
- Long context as scenario progresses

**Recommendations:**
- Always use `--dry-run` first to preview costs
- Set conservative budget limits (e.g., `budget_limit: 50.00`)
- Consider using `gpt-4o-mini` for most actors
- Test with `--max-turns 12` before full runs
- Use response caching (30-70% savings on repeated runs)

### Analyze Results

After batch completion:

```bash
python src/batch_analyzer.py scenarios/ai-2027/experiments/model-comparison/ --report
```

This enables:
- Identifying most likely outcome trajectories
- Finding critical factors that determine outcomes
- Testing robustness of different policies
- Sensitivity analysis on actor behaviors
- Model comparison (do cheaper models produce similar results?)

## Credits

This scenario is based on "AI 2027" by:
- Daniel Kokotajlo
- Scott Alexander
- Thomas Larsen
- Eli Lifland
- Romeo Dean

Full document: https://ai-2027.com/ai-2027.pdf

## License

The original AI 2027 document is used with permission for research purposes. This scenario configuration is provided for AI governance research and policy analysis.
